{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jfyODGSm9qD"
      },
      "source": [
        "# VGG16_LargeFOV\n",
        "\n",
        "## 1. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_colab = False\n",
        "use_gpu = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TQWfOOAgm9qR"
      },
      "outputs": [],
      "source": [
        "if use_colab:\n",
        "    ! git clone https://github.com/chendonghp/deeplab-v1.git\n",
        "    !pip install -U cython\n",
        "    !pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd deeplab-v1/Implementation/\n",
        "    ! unzip /content/drive/MyDrive/data.zip -d ./dataset\n",
        "    use_gpu = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s2qedW5Hm9qX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-17 19:34:00.135489: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-17 19:34:00.230485: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-17 19:34:00.801310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-17 19:34:00.801442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-17 19:34:00.920854: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-17 19:34:01.217235: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-17 19:34:01.220391: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-17 19:34:09.472341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Ignore Warning\n",
        "import json\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import train\n",
        "from data import LungImageDataset, colorDict, compute_mean_std\n",
        "\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svF6kF4goHCz",
        "outputId": "0757c056-b43b-42e2-b112-97cccfe48bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'DeepLab_v1 - SBD, VOC 2012.ipynb'    __init__.py       config.json   train.py\n",
            " Inference.ipynb\t\t      __pycache__       data.py       utils.py\n",
            " VGG16_LargeFOV_SBD,_VOC_2012.ipynb   augmentation.py   experiment\n",
            " VGG16_LargeFOV_SBD_VOC_2012.ipynb    best.pt\t        model.py\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u3zjKkwSm9qZ"
      },
      "outputs": [],
      "source": [
        "if use_colab:\n",
        "    data_root = r\"./dataset\"\n",
        "\n",
        "    # dataset\n",
        "    train_batch_size = 130\n",
        "    test_batch_size = 60\n",
        "    train_ratio = 0.9\n",
        "    size = 12000  # select num of images to put in dataset\n",
        "    train_size = int(size * train_ratio)\n",
        "    train_range, val_range = (0, train_size), (train_size, size)\n",
        "\n",
        "    # model parameters\n",
        "    num_classes = len(colorDict.keys())\n",
        "    ignore_index = 255\n",
        "\n",
        "    # train hyperparameters\n",
        "    epochs = 100\n",
        "    lr = 0.001\n",
        "    momentum = 0.9\n",
        "    weight_decay = 0.0005\n",
        "    init_weights = True\n",
        "\n",
        "    # log and save\n",
        "    print_freq = 5\n",
        "    epoch_print = 1\n",
        "    path = \"/content/drive/MyDrive/experiment/vgg16_largefov\"\n",
        "    load_path = path\n",
        "    save_path = path\n",
        "    log_path = path\n",
        "else:\n",
        "    data_root = r\"/mnt/d/data/\"\n",
        "    # dataset\n",
        "    train_batch_size = 20\n",
        "    test_batch_size = 20\n",
        "    train_ratio = 0.9\n",
        "    size = 1200  # select num of images to put in dataset\n",
        "    train_size = int(size * train_ratio)\n",
        "    train_range, val_range = (0, train_size), (train_size, size)\n",
        "\n",
        "    # model parameters\n",
        "    num_classes = len(colorDict.keys())\n",
        "    ignore_index = 255\n",
        "\n",
        "    # train hyperparameters\n",
        "    epochs = 20\n",
        "    lr = 0.001\n",
        "    momentum = 0.9\n",
        "    weight_decay = 0.0005\n",
        "    init_weights = True\n",
        "\n",
        "    # log and save\n",
        "    print_freq = 5\n",
        "    epoch_print = 1\n",
        "    path = \"experiment/vgg16_largefov\"\n",
        "    load_path = path\n",
        "    save_path = path\n",
        "    log_path = path\n",
        "\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8iG5nkwm9qa"
      },
      "source": [
        "## 2. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: [203.55824279785156, 162.8309783935547, 196.75608825683594]\n",
            "Std: [46.08964157104492, 68.10713958740234, 43.41297912597656]\n"
          ]
        }
      ],
      "source": [
        "mean = [189.88934326171875, 146.19163513183594, 185.65106201171875]\n",
        "std = [54.879695892333984, 71.9688720703125, 47.94575119018555]\n",
        "\n",
        "\n",
        "def image_mean_std():\n",
        "    dataset = LungImageDataset(\n",
        "        data_root,\n",
        "        transform=A.Compose([ToTensorV2()]),\n",
        "        size=(0, size),\n",
        "    )\n",
        "    dataset_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=200,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    if not os.path.exists(\"config.json\"):\n",
        "        print(\"config.json file does not exist, compute now\")\n",
        "        mean, std = compute_mean_std(dataset_loader)\n",
        "        mean, std = mean / 255, std / 255\n",
        "        mean, std = mean.tolist(), std.tolist()\n",
        "        data = {\"mean\": mean, \"std\": std}\n",
        "        with open(\"config.json\", \"w\") as f:\n",
        "            json.dump(data, f)\n",
        "        print(\"Mean:\", mean)\n",
        "        print(\"Std:\", std)\n",
        "    else:\n",
        "        with open(\"config.json\", \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        mean, std = data[\"mean\"], data[\"std\"]\n",
        "        print(\"Mean:\", mean)\n",
        "        print(\"Std:\", std)\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_tf = A.Compose(\n",
        "    [\n",
        "        A.Resize(256, 256),\n",
        "        A.RandomCrop(256, 256),\n",
        "        A.HorizontalFlip(),\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        ToTensorV2(True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_tf = A.Compose(\n",
        "    [A.Resize(256, 256), A.Normalize(mean=mean, std=std), ToTensorV2(True)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rGHNfEMsm9qb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train_dataset = LungImageDataset(data_root, size=train_range, transform=train_tf)\n",
        "val_dataset = LungImageDataset(data_root, size=val_range, transform=val_tf)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "# train_dataset = torchvision.datasets.SBDataset(root='./', image_set='train_noval', mode='segmentation', download=False, transforms=train_tf)\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "# val_dataset = torchvision.datasets.VOCSegmentation(root='./', year='2012', image_set='val', download=False, transforms=val_tf)\n",
        "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zM-adlurm9qd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([20, 3, 256, 256]), torch.Size([20, 1, 256, 256]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features, train_labels = next(iter(train_loader))\n",
        "train_features.shape, train_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hozsxKom9qg"
      },
      "source": [
        "## 3. Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sYUdmpDYm9qh",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "vgg16_largefov = train.VGG16_LargeFOV(\n",
        "    num_classes=num_classes,\n",
        "    init_weights=init_weights,\n",
        "    ignore_index=ignore_index,\n",
        "    use_gpu=use_gpu,\n",
        "    device=device,\n",
        "    print_freq=print_freq,\n",
        "    epoch_print=epoch_print,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6007 (pid 70079), started 1:58:52 ago. (Use '!kill 70079' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-e7a05e0ffa7f0282\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-e7a05e0ffa7f0282\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6007;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir  {path}/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CrO7EGoOm9qi",
        "outputId": "5a696bec-07b1-4333-d832-0c4fb7f323aa",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Started...\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 0 - Train Loss : 1.787662, Test Loss : 1.784521, Test mIoU : 8.5141, Test mpa : 11.3553\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "await vgg16_largefov.train(\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    load_path=None,\n",
        "    save_path=save_path,\n",
        "    log_path=log_path,\n",
        "    epochs=epochs,\n",
        "    lr=lr,\n",
        "    momentum=momentum,\n",
        "    weight_decay=weight_decay,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
