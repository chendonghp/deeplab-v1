{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jfyODGSm9qD"
      },
      "source": [
        "# VGG16_LargeFOV\n",
        "\n",
        "## 1. Environment Setup\n",
        "\n",
        "### 1.0. Check GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s2qedW5Hm9qX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-17 00:11:38.174744: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-17 00:11:38.240299: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-17 00:11:38.655598: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-17 00:11:38.655663: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-17 00:11:38.709667: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-17 00:11:38.899372: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-17 00:11:38.900707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-17 00:11:40.530668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from data import LungImageDataset, colorDict\n",
        "from torch.utils.data import DataLoader\n",
        "import augmentation\n",
        "import model\n",
        "import train\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Ignore Warning\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action=\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "use_colab = False\n",
        "use_gpu = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TQWfOOAgm9qR"
      },
      "outputs": [],
      "source": [
        "if use_colab:\n",
        "    ! git clone https://github.com/chendonghp/deeplab-v1.git\n",
        "    !pip install -U cython\n",
        "    !pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd deeplab-v1/Implementation/\n",
        "    ! unzip /content/drive/MyDrive/data.zip -d ./dataset\n",
        "    use_gpu = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svF6kF4goHCz",
        "outputId": "0757c056-b43b-42e2-b112-97cccfe48bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'DeepLab_v1 - SBD, VOC 2012.ipynb'    __init__.py       best.pt      model.py\n",
            " Inference.ipynb\t\t      __pycache__       data.py      train.py\n",
            " VGG16_LargeFOV_SBD,_VOC_2012.ipynb   augmentation.py   experiment   utils.py\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u3zjKkwSm9qZ"
      },
      "outputs": [],
      "source": [
        "if use_colab:\n",
        "    data_root = r\"./dataset\"\n",
        "\n",
        "    # dataset\n",
        "    train_batch_size = 130\n",
        "    test_batch_size = 60\n",
        "    train_ratio = 0.9\n",
        "    size = 12000  # select num of images to put in dataset\n",
        "    train_size = int(size * train_ratio)\n",
        "    train_range, val_range = (0, train_size), (train_size, size)\n",
        "\n",
        "    # model parameters\n",
        "    num_classes = len(colorDict.keys())\n",
        "    ignore_index = 255\n",
        "\n",
        "    # train hyperparameters\n",
        "    epochs = 100\n",
        "    lr = 0.001\n",
        "    momentum = 0.9\n",
        "    weight_decay = 0.0005\n",
        "    init_weights = True\n",
        "\n",
        "    # log and save\n",
        "    print_freq = 5\n",
        "    epoch_print = 1\n",
        "    path = \"/content/drive/MyDrive/experiment/vgg16_largefov\"\n",
        "    load_path = path\n",
        "    save_path = path\n",
        "    log_path = path\n",
        "else:\n",
        "    data_root = r\"/mnt/d/data/\"\n",
        "    # dataset\n",
        "    train_batch_size = 10\n",
        "    test_batch_size = 10\n",
        "    train_ratio = 0.9\n",
        "    size = 120  # select num of images to put in dataset\n",
        "    train_size = int(size * train_ratio)\n",
        "    train_range, val_range = (0, train_size), (train_size, size)\n",
        "\n",
        "    # model parameters\n",
        "    num_classes = len(colorDict.keys())\n",
        "    ignore_index = 255\n",
        "\n",
        "    # train hyperparameters\n",
        "    epochs = 20\n",
        "    lr = 0.001\n",
        "    momentum = 0.9\n",
        "    weight_decay = 0.0005\n",
        "    init_weights = True\n",
        "\n",
        "    # log and save\n",
        "    print_freq = 5\n",
        "    epoch_print = 1\n",
        "    path = \"experiment/vgg16_largefov\"\n",
        "    load_path = path\n",
        "    save_path = path\n",
        "    log_path = path\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8iG5nkwm9qa"
      },
      "source": [
        "## 2. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rGHNfEMsm9qb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train_tf = augmentation.Mask_Aug(\n",
        "    transforms=[\n",
        "        augmentation.ToTensor(),\n",
        "        augmentation.PILToTensor(),  # HWC to CHW\n",
        "        # augmentation.Resize((256, 256)),\n",
        "        augmentation.RandomCrop((224, 224)),\n",
        "        augmentation.RandomHorizontalFlip(),\n",
        "        # augmentation.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_tf = augmentation.Mask_Aug(\n",
        "    transforms=[\n",
        "        augmentation.ToTensor(),\n",
        "        augmentation.PILToTensor(),\n",
        "        # augmentation.Resize((256, 256)),\n",
        "        # augmentation.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = LungImageDataset(data_root, size=train_range, transform=train_tf)\n",
        "val_dataset = LungImageDataset(data_root, size=val_range, transform=val_tf)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "\n",
        "# train_dataset = torchvision.datasets.SBDataset(root='./', image_set='train_noval', mode='segmentation', download=False, transforms=train_tf)\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "# val_dataset = torchvision.datasets.VOCSegmentation(root='./', year='2012', image_set='val', download=False, transforms=val_tf)\n",
        "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zM-adlurm9qd"
      },
      "outputs": [],
      "source": [
        "train_features, train_labels = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwxzzRNim9qf",
        "outputId": "13a0125f-3043-491e-ca03-072bbfdb2815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10, 1, 224, 224]), torch.Size([10, 3, 224, 224]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels.shape, train_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hozsxKom9qg"
      },
      "source": [
        "## 3. Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sYUdmpDYm9qh",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "vgg16_largefov = train.VGG16_LargeFOV(\n",
        "    num_classes=num_classes,\n",
        "    init_weights=init_weights,\n",
        "    ignore_index=ignore_index,\n",
        "    use_gpu=use_gpu,\n",
        "    device=device,\n",
        "    print_freq=print_freq,\n",
        "    epoch_print=epoch_print,\n",
        ")\n",
        "\n",
        "# VGG16_LargeFOV = train.VGG16_LargeFOV(num_classes=num_classes, init_weights=init_weights, ignore_index=ignore_index,\n",
        "#                                       gpu_id=gpu_id, print_freq=print_freq, epoch_print=epoch_print)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 6239), started 0:03:48 ago. (Use '!kill 6239' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-22996c312fe2086\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-22996c312fe2086\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if use_colab:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir  {path}/runs\n",
        "else:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir  {path}/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CrO7EGoOm9qi",
        "outputId": "5a696bec-07b1-4333-d832-0c4fb7f323aa",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Started...\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 0 - Train Loss : 1.826583, Test Loss : 1.802277, Test mIoU : 0.8244, Test mpa : 0.8706\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 1 - Train Loss : 1.813102, Test Loss : 1.798792, Test mIoU : 1.2279, Test mpa : 1.3119\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 2 - Train Loss : 1.804427, Test Loss : 1.793897, Test mIoU : 2.0515, Test mpa : 2.2382\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 3 - Train Loss : 1.809717, Test Loss : 1.789275, Test mIoU : 2.9981, Test mpa : 3.3915\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Iteration : 4 - Train Loss : 1.799107, Test Loss : 1.783843, Test mIoU : 4.2007, Test mpa : 5.0047\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 4 - Train Loss : 1.799107, Test Loss : 1.783843, Test mIoU : 4.2007, Test mpa : 5.0047\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 5 - Train Loss : 1.796615, Test Loss : 1.777602, Test mIoU : 5.6594, Test mpa : 7.3332\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 6 - Train Loss : 1.789781, Test Loss : 1.771304, Test mIoU : 6.8270, Test mpa : 9.5379\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 7 - Train Loss : 1.783017, Test Loss : 1.764052, Test mIoU : 7.8432, Test mpa : 11.6389\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 8 - Train Loss : 1.779037, Test Loss : 1.757810, Test mIoU : 8.3835, Test mpa : 12.9915\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Iteration : 9 - Train Loss : 1.763263, Test Loss : 1.751227, Test mIoU : 8.5369, Test mpa : 13.6714\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 9 - Train Loss : 1.763263, Test Loss : 1.751227, Test mIoU : 8.5369, Test mpa : 13.6714\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_latest.pt.\n",
            "Epoch 1 Started...\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Bad pipe message: %s [b'nnection: keep-alive\\r\\nUpgrade-Insecure-Requests: 1\\r\\nUser-Agent: Mo', b'lla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Cursor/0.22.1 Chrome/114.0.5735.289 Electron', b'5.9.7 Safari/537.36\\r\\nAccept: text/html,applica']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Iteration : 4 - Train Loss : 1.729167, Test Loss : 1.704724, Test mIoU : 7.7139, Test mpa : 14.0193\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Iteration : 9 - Train Loss : 1.681343, Test Loss : 1.622072, Test mIoU : 7.8371, Test mpa : 15.1909\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_latest.pt.\n",
            "Epoch 2 Started...\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD,_VOC_2012.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m vgg16_largefov\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     train_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     val_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     load_path\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     save_path\u001b[39m=\u001b[39;49msave_path,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     log_path\u001b[39m=\u001b[39;49mlog_path,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/ddd/graduate/DeepLab_v1/Implementation/VGG16_LargeFOV_SBD%2C_VOC_2012.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# VGG16_LargeFOV.train(train_loader, val_loader, save=save, epochs=epochs, lr=lr, momentum=momentum, weight_decay=weight_decay)\u001b[39;00m\n",
            "File \u001b[0;32m~/graduate/DeepLab_v1/Implementation/train.py:162\u001b[0m, in \u001b[0;36mVGG16_LargeFOV.train\u001b[0;34m(self, train_loader, test_loader, load_path, save_path, log_path, epochs, lr, momentum, weight_decay)\u001b[0m\n\u001b[1;32m    159\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(output, y)\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 162\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    165\u001b[0m test_mIoU, test_loss, test_mpa \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(test_loader)\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "vgg16_largefov.train(\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    load_path=None,\n",
        "    save_path=save_path,\n",
        "    log_path=log_path,\n",
        "    epochs=epochs,\n",
        "    lr=lr,\n",
        "    momentum=momentum,\n",
        "    weight_decay=weight_decay,\n",
        ")\n",
        "# VGG16_LargeFOV.train(train_loader, val_loader, save=save, epochs=epochs, lr=lr, momentum=momentum, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
