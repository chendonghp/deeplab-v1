{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jfyODGSm9qD"
      },
      "source": [
        "# VGG16_LargeFOV\n",
        "\n",
        "## 1. Environment Setup\n",
        "\n",
        "### 1.0. Check GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s2qedW5Hm9qX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-17 17:32:44.790521: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-17 17:32:44.793535: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-17 17:32:44.855770: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-17 17:32:44.855819: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-17 17:32:44.857161: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-17 17:32:44.866423: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-17 17:32:44.868063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-17 17:32:46.480136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from data import LungImageDataset, colorDict\n",
        "from torch.utils.data import DataLoader\n",
        "# import augmentation\n",
        "import model\n",
        "import train\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Ignore Warning\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action=\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "use_colab = False\n",
        "use_gpu = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TQWfOOAgm9qR"
      },
      "outputs": [],
      "source": [
        "if use_colab:\n",
        "    ! git clone https://github.com/chendonghp/deeplab-v1.git\n",
        "    !pip install -U cython\n",
        "    !pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd deeplab-v1/Implementation/\n",
        "    ! unzip /content/drive/MyDrive/data.zip -d ./dataset\n",
        "    use_gpu = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svF6kF4goHCz",
        "outputId": "0757c056-b43b-42e2-b112-97cccfe48bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'DeepLab_v1 - SBD, VOC 2012.ipynb'    __pycache__       experiment   utils.py\n",
            " Inference.ipynb\t\t      augmentation.py   model.py\n",
            " VGG16_LargeFOV_SBD,_VOC_2012.ipynb   best.pt\t        test.py\n",
            " __init__.py\t\t\t      data.py\t        train.py\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u3zjKkwSm9qZ"
      },
      "outputs": [],
      "source": [
        "if use_colab:\n",
        "    data_root = r\"./dataset\"\n",
        "\n",
        "    # dataset\n",
        "    train_batch_size = 130\n",
        "    test_batch_size = 60\n",
        "    train_ratio = 0.9\n",
        "    size = 12000  # select num of images to put in dataset\n",
        "    train_size = int(size * train_ratio)\n",
        "    train_range, val_range = (0, train_size), (train_size, size)\n",
        "\n",
        "    # model parameters\n",
        "    num_classes = len(colorDict.keys())\n",
        "    ignore_index = 255\n",
        "\n",
        "    # train hyperparameters\n",
        "    epochs = 100\n",
        "    lr = 0.001\n",
        "    momentum = 0.9\n",
        "    weight_decay = 0.0005\n",
        "    init_weights = True\n",
        "\n",
        "    # log and save\n",
        "    print_freq = 5\n",
        "    epoch_print = 1\n",
        "    path = \"/content/drive/MyDrive/experiment/vgg16_largefov\"\n",
        "    load_path = path\n",
        "    save_path = path\n",
        "    log_path = path\n",
        "else:\n",
        "    data_root = r\"/mnt/d/data/\"\n",
        "    # dataset\n",
        "    train_batch_size = 10\n",
        "    test_batch_size = 10\n",
        "    train_ratio = 0.9\n",
        "    size = 120  # select num of images to put in dataset\n",
        "    train_size = int(size * train_ratio)\n",
        "    train_range, val_range = (0, train_size), (train_size, size)\n",
        "\n",
        "    # model parameters\n",
        "    num_classes = len(colorDict.keys())\n",
        "    ignore_index = 255\n",
        "\n",
        "    # train hyperparameters\n",
        "    epochs = 20\n",
        "    lr = 0.001\n",
        "    momentum = 0.9\n",
        "    weight_decay = 0.0005\n",
        "    init_weights = True\n",
        "\n",
        "    # log and save\n",
        "    print_freq = 5\n",
        "    epoch_print = 1\n",
        "    path = \"experiment/vgg16_largefov\"\n",
        "    load_path = path\n",
        "    save_path = path\n",
        "    log_path = path\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8iG5nkwm9qa"
      },
      "source": [
        "## 2. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.json file does not exist, compute now\n",
            "Mean: [191.48016357421875, 141.48892211914062, 183.9773406982422]\n",
            "Std: [50.47390365600586, 68.20906829833984, 44.792720794677734]\n"
          ]
        }
      ],
      "source": [
        "# compute image mean and std\n",
        "from data import compute_mean_std\n",
        "import json\n",
        "# Using Albumentations library for data augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "dataset = LungImageDataset(\n",
        "    data_root,\n",
        "    transform=A.Compose(\n",
        "        [ToTensorV2()]\n",
        "    ),\n",
        "    size=(0, size),\n",
        ")\n",
        "dataset_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=200,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "if not os.path.exists(\"config.json\"):\n",
        "    print(\"config.json file does not exist, compute now\")\n",
        "    mean, std = compute_mean_std(dataset_loader)\n",
        "    mean, std = mean.tolist(), std.tolist()\n",
        "    data = {\"mean\": mean, \"std\": std}\n",
        "    with open(\"config.json\", \"w\") as f:\n",
        "        json.dump(data, f)\n",
        "    print(\"Mean:\", mean)\n",
        "    print(\"Std:\", std)\n",
        "else:\n",
        "    with open(\"config.json\", \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    mean, std = data[\"mean\"], data[\"std\"]\n",
        "    print(\"Mean:\", mean)\n",
        "    print(\"Std:\", std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_tf = A.Compose(\n",
        "    [A.Resize(256, 256), A.RandomCrop(256, 256), A.HorizontalFlip(), A.Normalize(mean=mean, std=mean), ToTensorV2(True)]\n",
        ")\n",
        "\n",
        "val_tf = A.Compose([A.Resize(256, 256), A.Normalize(mean=mean, std=mean), ToTensorV2(True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rGHNfEMsm9qb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train_dataset = LungImageDataset(data_root, size=train_range, transform=train_tf)\n",
        "val_dataset = LungImageDataset(data_root, size=val_range, transform=val_tf)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "# train_dataset = torchvision.datasets.SBDataset(root='./', image_set='train_noval', mode='segmentation', download=False, transforms=train_tf)\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "# val_dataset = torchvision.datasets.VOCSegmentation(root='./', year='2012', image_set='val', download=False, transforms=val_tf)\n",
        "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zM-adlurm9qd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10, 3, 256, 256]), torch.Size([10, 1, 256, 256]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features, train_labels = next(iter(train_loader))\n",
        "train_features.shape, train_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hozsxKom9qg"
      },
      "source": [
        "## 3. Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sYUdmpDYm9qh",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "vgg16_largefov = train.VGG16_LargeFOV(\n",
        "    num_classes=num_classes,\n",
        "    init_weights=init_weights,\n",
        "    ignore_index=ignore_index,\n",
        "    use_gpu=use_gpu,\n",
        "    device=device,\n",
        "    print_freq=print_freq,\n",
        "    epoch_print=epoch_print,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Launching TensorBoard..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if use_colab:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir  {path}/runs\n",
        "else:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir  {path}/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CrO7EGoOm9qi",
        "outputId": "5a696bec-07b1-4333-d832-0c4fb7f323aa",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Started...\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "\n",
            " *********************************** Best mIoU Updated ***********************************\n",
            "Iteration : 0 - Train Loss : 1.791929, Test Loss : 1.793070, Test mIoU : 3.0458, Test mpa : 3.4965\n",
            "Saved Model at experiment/vgg16_largefov/vgg16_large_fov_best.pt.\n",
            "\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Iteration : 4 - Train Loss : 1.788671, Test Loss : 1.791071, Test mIoU : 2.4045, Test mpa : 2.6342\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n",
            "Training log saved to experiment/vgg16_largefov/vgg_largefov_training_log.csv.\n"
          ]
        }
      ],
      "source": [
        "vgg16_largefov.train(\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    load_path=None,\n",
        "    save_path=save_path,\n",
        "    log_path=log_path,\n",
        "    epochs=epochs,\n",
        "    lr=lr,\n",
        "    momentum=momentum,\n",
        "    weight_decay=weight_decay,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
